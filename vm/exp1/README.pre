# Experimental minimal virtual machine from the ground up

# TODO really should start with the bit.

It starts with a byte.

Consisting of 8 bits (binary digits) that are either 0 are 1, the byte is a
fundamental unit of data representation.

### TODO set `d`s in italic or something to make them stand out

It can be used to represent 2^8 = 256 different integers, and this is where
we'll start.  To show the binary representation of a number, we say
`0b<dddddddd>`, where `d`s denote the bits of the byte, from the most
significant to the least significant.  If there number of `d`s is less than 8,
the highest digits are taken to be zero.  This lets us represent the integers 0
(0b00000000) to 255 (0b11111111).  Right now, we'll concern ourselves with just
nonnegative integers.

Memory is an area with many bytes, said to consist of memory cells that can hold
one byte of data.

So that we can refer to an individual memory cell, we give each one an address.
The address is simply a number starting from zero.  The first cell has address
0, the second one has address 1, and so on.  An address is said to /point/ at a
memory cell (or to the byte therein); often, we talk about /pointers/ when we
mean addresses.

We now design and implement a machine that performs operations on the bytes in
the memory.

The machine does all sorts of things to these bytes.  Basically they perform
computation.  We might ask the machine to add byte at memory location 1 to a
byte at memory location 0.  This is called an instruction.

To encode the instruction in a form that computer can efficiently read, it is
represented as a number.  For simplicity, it's useful to keep that number the
same size (even though many real-world machine languages instructions of
different lengths).  How big a number should we pick for the instruction?  The
computer loves multiples of 8 bits, and especially numbers that are of the form
`8 * 2^n`.  We pick 32 bits, since that lets us nicely represent a good spectrum
of instructions while not usually wasting too much space.

The bit representation of the instruction is: 

	0b<oooooooo_aaaaaaaa_aaaabbbb_bbbbbbbb>

(The underscores do not have a semantic significance; they are there as
signposts to help the reader make a sense out of the number.)

Let's say that O is the number denoted by the 8 bits marked with o; similarly, A
is the 12-bit number denoted by a's, and B by b's.  The O is called /opcode/ and
denotes the operation that we want to do.  `A` and `B` are called /operands/,
and they determine what the instruction operates on.  `A`, the /target/ operand,
points to a memory location we want to change;  `B` points to memory location
whose contents we use to change it.  The memory location at `B` will never be
changed.

We give some commonly used operations opcodes starting from 0: 0 is add, 1 is
subtract, 2 is multiply, 3 division, 4 modulo, and so on.  We'll just
implement these for now.

## Instruction table

	00000000 add a, b      add b to a
	00000001 sub a, b      subtract b from a
	00000010 mul a, b      multiply a with b
	00000011 div a, b      divide a by b, leave the quotient part
	00000100 mod a, b      divide a by b, leave the remainder part

The instruction number 4 (0b0100) is called `mod` even though its description
talks about the remainder; this is because for nonnegative numbers, the _modulo
operation_ (http://en.wikipedia.org/wiki/Modulo_operation) is equivalent to
taking the remainder of the division.

The instructions live in a memory like the data they operate on, only it is a
different kind of memory.  It, too, has addresses like the data memory: the
number 0 means the first instruction, and so on.

There is a special memory location called `pc`, short for /program counter/,
that points to the next instruction that the machine will execute.

With this newly armed instruction set, we can write our first program.  We
compute the product (1 + 2) * 3 and place the result in memory location 0.  We
data must preexist in the memory before we start to execute the program (we'll
eventually have a means to load arbitrary data into memory, but not yet.) This
is the initial state of the memory:

	00000001 00000010 00000011

Bytes at addresses 0, 1, and 2 contain the number 1, 2, and 3, respectively.

Here is our program.  We have annotated it with a notation where `m[<number>]`
means the memory cell at `<number>`.

### TODO comments

	// add m[0b00000001] to m[0b00000000] 
	00000000 00000000 00000000 00000001

	// multiply m[0b00000000] with m[0b00000010]
	00000010 00000000 00000000 00000010  

How does the machine know when to stop executing?  For that, we have a special
instruction `exit`, which only takes one address, whose contents it presents as
a result.  The exit instruction has the following bit representation:

00001111 00000000 0000aaaa aaaaaaaa

Note that even though the exit instruction has space for the target operand, it
is never used.  In fact, the bits usually reserved for the target operand may
contain anything; the machine does not care.  But there is a convention that
they are always set to zero.  By doing this, we effectively reserve a block in
the instruction space that we may later reuse for other purposes if we so
choose.

Sometimes it's useful to use a certain value without having it stored in the
memory.  For that, we store the value in the instruction itself.  To communicate
to the machine that we mean the number itself instead of the byte that it points
to, we set the highest bit of the number to 1.  We call these values that are
embedded in the instruction /immediate values/.

iiiiiiii aaaaaaaa aaaa1bbb bbbbbbbb

The astute reader will immediately notice two things: first, we may not use an
immediate value as the target, since that does not make any sense (aside:
it would certainly be possible to make a machine where numbers could be
modified. However, it would be inefficient, and more importantly, inconvenient,
since it would make reasoning about programs rather difficult.) and second, that
we have whole 11 bits for representing the value, even though our world only
consists of 8-bit values.  This might seem like a waste, but rest assured that
eventually the bits will find a good use.  For now, the machine will only look
at the lowest 8 bits.

## Implementing the virtual machine

Here's a straightforward C++ implementation of the virtual machine.

It imports `stdio` for input and output, and defines shorthands for types we use:

	#include <stdio.h>

	typedef unsigned char byte;
	typedef unsigned int uint32;

Next, we define the data and code.  We have 1024 bytes for data and and 1024*4
bytes for instructions.

	const uint32 data_size = 1024;
	const uint32 code_size = 1024;

	byte m[data_size] = {
		0x01,
		0x02,
		0x03
	};

	uint32 code[code_size] = {
		0x00000001, // add m[0], m[1]
		0x02000002, // mul m[0], m[2]
		0x0f000000, // exit m[0]
	};

To decode the instructions, we define a handful of masks:

	const int opcode_bits = 8;
	const int opcode_mask = (1 << opcode_bits) - 1;
	const int a_bits = 12;
	const int a_mask = (1 << a_bits) - 1;
	const int b_bits = 12;
	const int b_mask = (1 << b_bits) - 1;

The opcodes we support are:

	const int op_add = 0x00;
	const int op_sub = 0x01;
	const int op_mul = 0x02;
	const int op_div = 0x03;
	const int op_mod = 0x04;

	const int op_exit = 0x0f;

A simple error handling function:

	void fail(const char* msg) {
		printf("%s\n", msg);
		exit(1);
	}

The main program initializes pc to the first instruction and enters the
instruction decode loop:

	int main() {
		uint32 pc = 0;

		while (true) {
			...
		}
	}

The decode loop first checks that `pc` is within bounds:

			if (pc >= code_size) {
				fail("invalid pc");
			}

It decodes the instruction:

			uint32 instr = code[pc++];
			uint32 b = instr & b_mask;
			uint32 a = (instr >> b_bits) & b_mask;
			uint32 opcode = (instr >> (a_bits + b_bits)) & opcode_mask;

The following line is useful when debugging:

			//printf("instr: %08x, op: %02x, a: %03x, b: %03x\n", instr, opcode, a, b);

Check that `a` is valid, and introduce `a_mem`, which is a pointer to the data:

			if (a >= data_size) {
				fail("invalid memory access (a)");
			}

			byte* a_mem = &m[a];

Since `b` can be an immediate value, it requires slightly different treament:

			byte b_immediate;
			byte* b_mem;
			// Immediate?
			if (b & (1 << 11)) {
				b_immediate = b & ((1 << 11) - 1);
				b_mem = &b_immediate;
			} else {
				if (b >= data_size) {
					fail("invalid memory access (b)");
				}
				b_mem = &m[b];
			}

Then we do the right thing depending on the operator:

			switch (opcode) {
				case op_exit:
					printf("exit with value %d\n", *b_mem);
					return 0;
				case op_add:
					*a_mem += *b_mem;
					break;
				case op_sub:
					*a_mem -= *b_mem;
					break;
				case op_mul: 
					*a_mem *= *b_mem;
					break;
				case op_div: 
					*a_mem /= *b_mem;
					break;
				case op_mod: 
					*a_mem %= *b_mem;
					break;
				default:
					fail("invalid instruction\n");
			}

## From machine code to assembly language

To represent the program and its data in a more human-readable (and, less
importantly, human-writable) way, we write it in an "assembly language" from
which a program might "assemble" it into machine code.

This makes our programs easier to write, and more importantly, easier to read.

Here's how our program might look in an assembly language.  The program has two
parts: first, we declare the data that we want to fill the memory with; then we
write the program that will operate on that data.  Each part consists of
/statements/; the statements in the first part are called /data declaration
statements/, and the statements in the second part are called /instruction
statements/.

	byte 1; // initialize m[0] with 1
	byte 2; // initialize m[1] with 2
	byte 3; // initialize m[2] with 3

	add m[0], m[1];
	mul m[0], m[2];
	exit m[0];

In principle, we could intersperse data declaration statements and instruction
statements, and soon we will.  But it is important to keep in mind that the two
go into two distinct memory spaces.

The `byte` statements determine the contents of the memory.  After the last
`byte` comes the program.  Instructions take the form `<operation> target,
source;` or just `<operation> source;` when there is no target.  We use the

### TODO implement assembler

We'll write the assembler in a little language called CoffeeScript -- it's terse
syntax and the power of regular expressions lets us express our assembler
succinctly.

TODO explain relevant parts of `asm1`.

The denotation may seem strange.  However, it lets us easily express programs
that use immediate values;

	byte 1;

	add(*0, 2);
	mul(*0, 3);
	exit(*0);

To make things even easier, we might give names to the memory addresses.  Let's
call the first memory address 'result'.  The assembler must now become smarter:
it has to keep track of names and the memory locations associated with them; and
when the names are used, it must fetch the memory location associated with the
name.

A named memory address is called a /variable/.  To /declare/ a variable, we adopt
the following syntax:

	byte <variable> = <number>;

This variable declaration tells the assembler to allocate space for
`<variable>`, and initialize that memory location with `<number>`.

The first variable is at memory location 0, the second at memory location 1,
etc.  The program can simply use the variable's name when it wants to address
that memory location.

Converted to use variables, the original program looks like:

	byte result = 1;
	byte two = 2;
	byte three = 3;

	add(result, two);
	mul(result, three);
	exit(result);

### TODO negative numbers, signed and unsigned operations 

### Arithmetic operators

### TODO Storing number to memory, fetching numbers from memory

Suppose we want to read a number from a memory location (say, 0), and store it
in another memory location (say, 1).

With our current instruction set, it is certainly possible.  We can do

	mul(*1, 0);
	add(*1, *0);

This program first sets *1 to zero, and then adds *0 to it.  It accomplishes our
goal, but it is not an ideal solution.  To be maximally readable, a program
should communicate what it tries to do at the right level of abstraction.  So we
should have an instruction to do that, and that instruction is called `set`.

	set(a, b);

`set` reads `b`, and writes into `a`.  `a` is a memory address, and `b` may be a
memory address or an immediate value.

The bit representation for `set` is



A program should always 

Could we replace it with a simpler program
A single-instruction program
It would be more readable to just
encode this program like this:

	set(

It is a program
an idea screaming for a shortcut
it makes reading programs harder, and it forces
us to use two pri

# From bytes to integers

We can write many useful programs with our little machine, but 8 bits only gets
you so far.  To perform operations on larger numbers, we need to expand our
horizons.  Let's start to use 16-bit, 32-bit, and 64-bit numbers.  

	-> conversion instructions

Little endian

	-> 



# Stack

Stack is a tool for unfinished computation.

I want to do something 

It's useful 

# Selection

"If this, do that"

ifeq, ifne, iflt, ifgt, ifle, ifge

# Macros

Remember the "a program should always communicate what it wants to do..."

Then, we solved our problem of moving `x` to `y` by saying `mul x, 0; add x,
y;`.  The right level of abstraction was achieved by introducing a new
instruction 

macros:

macro plus(x, y) {
	result = x;
	add(result, y);
}

* are inlined and typeless
* special variable `result` 
* how do they work

Since we control both our instruction set and are equipped by the ability to
write macros, which one should we choose when creating a new abstraction? 

This is a delicate question, which requires careful balancing of several
variables: the simplicity of the instruction set (helps understandability and
makes it easier to write an efficient implementation (+ verifiable)), the
length of the expanded code, ...

Right now, our instruction set is rather simple and there is quite a
bit of room to expand it, so the emphasis is on building the instruction set.
When longer, more complex, and not less generally useful abstractions are
required, macros are a better bet.  The equation will further be complicated
when new means of abstraction become available.  

# Types (selecting macro based on argument types)

macro plus(ref int64 a, ref int64 b) {
	result = a;
	add64(result, b)
}

macro int8 plus(ref int8 a, ref int8 b) {
	result = a;
	add8(result, b);
}

# Functions

Macros are useful for avoid repetition, but they have one deficiency: they
cannot refer to themselves, even indirectly, since the macro expansion would be
infinitely big.  We would like to have the opportunity of choosing whether to
expand a macro based on the data available to it during the run time.  But this
is not possible, since macro expansions are done during compile time.

The solution is a /function/: a block of code that we can /call/, passing it
some values in the stack, and that will produce a value in the stack when it
returns.  Functionally, calling a function is equivalent to calling a macro: it
will consume items from the stack, and leave its return value on the top of the
stack.  But functions have the additional perk of being able to call themselves.
Also, if you have lots of repeated code, you can compress it by taking repeated
pieces of code, making a function out the repeated code, and replacing the
original code sequences by function calls.  (aside: We call this kind of
activity /refactoring/: changing of the code so that its meaning won't change,
but its other properties, such as size, readability, or efficiency, change
(hopefully for the better!).  A refactoring can also go into the other
direction: if a function is only called once, it may make sense to make it a
macro, or by manually insert the function's code into the location where it is
called.).

# TODO fp and calling sequence

# TODO really equivalent to macros? Do macro calls first push a return value to
# the stack?  Guess they do, since they don't push the arguments at all.

A function for finding out the length of a linked list might look like this:

	int32 list_size(int32 head) {
		ifne(head, 0);
		goto(nonzero);
		// TODO check that this is the correct location for return value
		// 'result' might always refer to *(fp + 2 + argc)
		set(*(fp + 3), 0);
		ret();
	nonzero:
		push(*head); // TODO let's see how double dereferences happen
		call(list_size);
		set(*(fp + 3), 1);
		add(*(fp + 3), *sp);
		ret();
	}

# Operator overloading

	a + b => add(a, b)
	a + b * c => add(a, add(b, c))

# Types (structs)

types:

	type Pair {
		int32 first;
		int32 second;
	}

Then declaring `Pair pair;` and saying `add(pair.first, pair.second)` has
exactly the same effect as if you had declared the variables `int32 pair.first;`
and `int32 pair.second;`

Suppose we wanted to give the Pair's contents default values.  This works, of
course:

	type Pair {
		int32 first = 1;
		int32 second = 2;
	}

Again, it has exactly the same effect as if you had declared the variables
`int32 pair.first = 1;` and `int32 pair.second = 2;`.  But what if we don't know
the proper default values for `first` and `second` until we declare a pair?  Or
what if we want to declare two pairs with different values?

For that, we'll write a /constructor/.  A constructor is like a macro, but it is
automatically called when a variable is declared.

Macro constructor:

	type Pair {
		macro init(first, second) {
			this.first = first;
			this.second = second;
		}
	}

To call a constructor, use the syntax:

	Pair pair = (1, 2);


The compiler knows to allocate space for two int32's inside Pair, since you
declared them inside it.  But what if you don't want to declare anything inside
a type? In that case, we can just specify the size of a type without determining
what goes inside.

type Buffer (1024) {
	
}

This allocates a buffer of 1024 bytes, which you can use as you like.

But what if we don't know the length until we declare the variable?

Buffer b;

type Bytes<n> (n) {
	
}

-> Array

type Array<T, n> (T.size * n) {
	macro at(n) {
		...
	}
}

In fact, even types like int32 are in no way special; you can define it by saying:

type int32 (4) {
	macro init(value) {
		// TODO real instruction
		this = value;
	}
}

TODO how to solve discrepancy between pre-baked global ints and local ones that
need initialization?

* Arrangement of things by saying `type Registers { int32 foo @ 16; int32 bar
  @ 20; ` etc; and then (globally) `Registers registers @ 0x1000`.




later...

## negative integers

represent the nonnegative integers 0..127 with binary representation
00000000..01111111, and the negative integers -128..-1 with binary
representation 10000000..11111111

